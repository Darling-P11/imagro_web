import { Injectable } from '@angular/core';
import * as tf from '@tensorflow/tfjs';
import { getStorage, ref, getDownloadURL } from "firebase/storage";

@Injectable({
  providedIn: 'root'
})
export class TensorflowService {
  modelo!: tf.LayersModel;

  constructor() {}

  // ğŸ”¹ Cargar modelo base MobileNetV2
  async cargarModeloPreEntrenado() {
    console.log("ğŸ“¥ Cargando MobileNet V1...");
  
    try {
      // ğŸ”¹ Carga MobileNet V1 Preentrenado desde TensorFlow.js
      const baseModel = await tf.loadLayersModel(
        'https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json'
      );
  
      console.log("âœ… MobileNet V1 cargado con Ã©xito.");
  
      // ğŸ”¹ Extraer caracterÃ­sticas hasta la Ãºltima capa convolucional
      const featureExtractor = tf.model({
        inputs: baseModel.inputs,
        outputs: baseModel.getLayer('conv_pw_13_relu').output // Ãšltima capa convolucional
      });
  
      console.log("ğŸ“Š Capas del modelo:", featureExtractor.layers.map(layer => layer.name));
  
      return featureExtractor;
    } catch (error) {
      console.error("âŒ Error al cargar MobileNet V1:", error);
      return null;
    }
  }
  
  
  

  // ğŸ”¹ Obtener URL de imagen desde Firebase Storage
  async obtenerImagenURL(imagenPath: string): Promise<string | null> {
    try {
      const storage = getStorage();
      const imagenRef = ref(storage, imagenPath);
      return await getDownloadURL(imagenRef);
    } catch (error) {
      console.warn(`âš ï¸ No se encontrÃ³ la imagen en Firebase: ${imagenPath}`);
      return null;
    }
  }

  // ğŸ”¹ Entrenar modelo con imÃ¡genes seleccionadas
  async entrenarModelo(
    featureExtractor: tf.LayersModel,
    imagenes: string[],
    callbackProgreso: (progreso: number) => void
  ) {
    console.log("ğŸš€ Iniciando entrenamiento con MobileNet V1...");
    callbackProgreso(10);
  
    try {
      // ğŸ”¹ Cargar y procesar imÃ¡genes
      const dataset = await this.cargarYPreprocesarImagenes(imagenes, featureExtractor);
      callbackProgreso(30);
  
      // ğŸ”¹ Crear el modelo de clasificaciÃ³n
      const numClases = dataset.ys.shape[1] || 2; // MÃ­nimo 2 clases
      const model = tf.sequential();
  
      // âœ… Ajuste: No aplanar la entrada, sino usar la misma forma del feature extractor
      model.add(tf.layers.inputLayer({ inputShape: [7, 7, 256] })); // Usa la forma correcta
  
      model.add(tf.layers.conv2d({ filters: 64, kernelSize: 3, activation: 'relu' }));
      model.add(tf.layers.flatten()); // ğŸ”¹ Ahora sÃ­ se aplana despuÃ©s de la convoluciÃ³n
      model.add(tf.layers.dense({ units: 128, activation: 'relu' }));
      model.add(tf.layers.dropout({ rate: 0.3 })); // ğŸ”¹ Evitar sobreajuste
      model.add(tf.layers.dense({ units: numClases, activation: 'softmax' })); // ğŸ”¹ ClasificaciÃ³n
  
      // ğŸ”¹ Agregamos mÃ©tricas adicionales
      model.compile({
        optimizer: tf.train.adam(),
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy', 'precision', 'recall']
      });
  
      console.log("âœ… Modelo de Transfer Learning compilado.");
  
      // ğŸ”¹ Entrenar el modelo
      await model.fit(dataset.xs, dataset.ys, {
        epochs: 10,
        batchSize: 16,
        validationSplit: 0.2,
        callbacks: {
          onEpochEnd: (epoch, logs) => {
            const progreso = Math.round(((epoch + 1) / 10) * 100);
            callbackProgreso(progreso);
            console.log(`ğŸ“Š Epoch ${epoch + 1}: Accuracy = ${logs?.['accuracy']}`);
            console.log(`ğŸ“Š Precision: ${logs?.['precision']} | Recall: ${logs?.['recall']}`);
          }
        }
      });
  
      console.log("ğŸ‰ Entrenamiento finalizado.");
      callbackProgreso(100);
      return model;
    } catch (error) {
      console.error("âŒ Error en entrenamiento:", error);
      callbackProgreso(0);
      return null;
    }
  }
  

  

  // ğŸ”¹ Guardar el modelo entrenado
  async guardarModelo(model: tf.LayersModel) {
    console.log("ğŸ’¾ Guardando el modelo en formato JSON...");
    try {
      await model.save('downloads://mobilenetv1_model');
      console.log("âœ… Modelo guardado correctamente.");
    } catch (error) {
      console.error("âŒ Error al guardar el modelo:", error);
    }
  }
  

  // ğŸ”¹ Preprocesamiento de imÃ¡genes
  async cargarYPreprocesarImagenes(imagenes: string[], featureExtractor: tf.LayersModel) {
    console.log("ğŸ“¥ Descargando imÃ¡genes desde Firebase Storage...");

    const xs: tf.Tensor[] = [];
    const ys: number[] = [];
    const storage = getStorage();
    const etiquetasMap = new Map<string, number>(); // Para rastrear las clases Ãºnicas
    let claseIndex = 0;

    for (const imagenPath of imagenes) {
        try {
            console.log(`ğŸ”— Intentando descargar: ${imagenPath}`);

            const imagenRef = ref(storage, imagenPath);
            let imagenUrl: string;

            try {
                imagenUrl = await getDownloadURL(imagenRef);
                console.log(`âœ… Imagen encontrada: ${imagenUrl}`);
            } catch (error) {
                console.warn(`âš ï¸ Imagen ${imagenPath} no encontrada en Firebase Storage. Omitiendo...`);
                continue;
            }

            const response = await fetch(imagenUrl);
            if (!response.ok) {
                throw new Error(`âŒ No se pudo descargar la imagen: ${imagenUrl}`);
            }

            const blob = await response.blob();
            const imageBitmap = await createImageBitmap(blob);

            // ğŸ”¹ Convertir imagen a tensor asegurando las dimensiones correctas
            let imgTensor = tf.browser.fromPixels(imageBitmap);
            imgTensor = tf.image.resizeBilinear(imgTensor, [224, 224]); // Redimensionar
            imgTensor = imgTensor.div(255.0); // Normalizar valores entre 0 y 1
            imgTensor = imgTensor.expandDims(0); // Asegurar batch de 1

            console.log("ğŸ“Š Forma del tensor antes de pasar por MobileNet:", imgTensor.shape);

            // ğŸ”¹ Extraer caracterÃ­sticas con MobileNet V1
            let featureTensor = featureExtractor.predict(imgTensor) as tf.Tensor;
            console.log("ğŸ” Forma original del tensor de caracterÃ­sticas:", featureTensor.shape);

            xs.push(featureTensor); // âœ… Ahora pasamos el tensor tal cual, sin aplanarlo

            // ğŸ”¹ Obtener etiqueta de la imagen desde la estructura de rutas
            const parts = imagenPath.split('/');
            const categoria = parts[parts.length - 2];

            if (!etiquetasMap.has(categoria)) {
                etiquetasMap.set(categoria, claseIndex++);
            }

            ys.push(etiquetasMap.get(categoria)!); 

        } catch (error) {
            console.error(`âŒ Error al procesar imagen ${imagenPath}:`, error);
        }
    }

    console.log(`ğŸ“Š Clases detectadas: ${Array.from(etiquetasMap.keys())}`);
    console.log(`ğŸ“Š NÃºmero total de clases: ${etiquetasMap.size}`);

    if (xs.length === 0) {
        throw new Error("âš ï¸ Error: No se pudieron cargar imÃ¡genes vÃ¡lidas.");
    }

    if (etiquetasMap.size < 2) {
        throw new Error("âš ï¸ Error: Se necesita al menos 2 clases para entrenamiento.");
    }

    // ğŸ”¹ Concatenar todas las caracterÃ­sticas extraÃ­das sin aplanar
    const xsTensor = tf.concat(xs);
    const numClases = etiquetasMap.size;
    const ysTensor = tf.oneHot(tf.tensor1d(ys, 'int32'), numClases);

    return { xs: xsTensor, ys: ysTensor };
}

// PROBAR MODELO
async cargarModeloGuardado() {
  console.log("ğŸ“¥ Cargando modelo guardado...");
  try {
      const model = await tf.loadLayersModel('/assets/mobilenetv1_model.json'); // Ruta en tu proyecto
      console.log("âœ… Modelo cargado correctamente.");
      return model;
  } catch (error) {
      console.error("âŒ Error al cargar el modelo:", error);
      return null;
  }
}




}
